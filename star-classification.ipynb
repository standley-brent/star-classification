{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "9b2c2bea-78c9-4395-bff6-1bc9888f2370",
   "display_name": "'Python Interactive'"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import requests\n",
    "import matplotlib as plt \n",
    "import seaborn as sns \n",
    "import pandas_profiling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.isthe.com/chongo/tech/astro/HR-temp-mass-table-byhrclass.html#below\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data = pd.DataFrame()\n",
    "html = pd.read_html(url)\n",
    "for i in html:\n",
    "    star_data = pd.concat([star_data, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1242"
      ]
     },
     "metadata": {},
     "execution_count": 350
    }
   ],
   "source": [
    "len(star_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data.drop([0, 1, 2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "source": [
    "len(star_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data['color_decimal'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_cleaner(rgb_text):\n",
    "    temp_split = rgb_text.split()\n",
    "    red = int(temp_split[0])\n",
    "    green = int(temp_split[1])\n",
    "    blue = int(temp_split[2])\n",
    "    color_hex = '%02x%02x%02x' % (red, green, blue)\n",
    "    color_finished = int(color_hex, 16)\n",
    "    return color_finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data['color_decimal'] = [rgb_cleaner(i) for i in star_data['Star ColorRGB 0-255']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data.drop(['Star ColorRGB 0-255'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data['star_family'] = [i[0] for i in star_data['StellarType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_data = pd.get_dummies(star_data, columns=['star_family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Abs MagMv  Bolo CorrBC(Temp)  Bolo MagMbol  Color IndexB-V  \\\n",
       "1231       13.1              -0.45         12.65           -0.07   \n",
       "1232       13.7              -0.20         13.50            0.09   \n",
       "1233       14.2              -0.09         14.11            0.34   \n",
       "1234       14.8              -0.10         14.70            0.55   \n",
       "1235       15.4              -0.22         15.18            0.74   \n",
       "\n",
       "      LuminosityLstar/Lsun  MassMstar/Msun  RadiusRstar/Rsun StellarType  \\\n",
       "1231              0.000693             0.5           0.00890         DZ5   \n",
       "1232              0.000315             0.4           0.00864         DZ6   \n",
       "1233              0.000180             0.3           0.00889         DZ7   \n",
       "1234              0.000105             0.2           0.00887         DZ8   \n",
       "1235              0.000067             0.1           0.00898         DZ9   \n",
       "\n",
       "        TempK  color_decimal star_family  \n",
       "1231  10080.0       13622015           D  \n",
       "1232   8400.0       14739199           D  \n",
       "1233   7200.0       15987711           D  \n",
       "1234   6300.0       16775157           D  \n",
       "1235   5600.0       16773089           D  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abs MagMv</th>\n      <th>Bolo CorrBC(Temp)</th>\n      <th>Bolo MagMbol</th>\n      <th>Color IndexB-V</th>\n      <th>LuminosityLstar/Lsun</th>\n      <th>MassMstar/Msun</th>\n      <th>RadiusRstar/Rsun</th>\n      <th>StellarType</th>\n      <th>TempK</th>\n      <th>color_decimal</th>\n      <th>star_family</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1231</th>\n      <td>13.1</td>\n      <td>-0.45</td>\n      <td>12.65</td>\n      <td>-0.07</td>\n      <td>0.000693</td>\n      <td>0.5</td>\n      <td>0.00890</td>\n      <td>DZ5</td>\n      <td>10080.0</td>\n      <td>13622015</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1232</th>\n      <td>13.7</td>\n      <td>-0.20</td>\n      <td>13.50</td>\n      <td>0.09</td>\n      <td>0.000315</td>\n      <td>0.4</td>\n      <td>0.00864</td>\n      <td>DZ6</td>\n      <td>8400.0</td>\n      <td>14739199</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>14.2</td>\n      <td>-0.09</td>\n      <td>14.11</td>\n      <td>0.34</td>\n      <td>0.000180</td>\n      <td>0.3</td>\n      <td>0.00889</td>\n      <td>DZ7</td>\n      <td>7200.0</td>\n      <td>15987711</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>14.8</td>\n      <td>-0.10</td>\n      <td>14.70</td>\n      <td>0.55</td>\n      <td>0.000105</td>\n      <td>0.2</td>\n      <td>0.00887</td>\n      <td>DZ8</td>\n      <td>6300.0</td>\n      <td>16775157</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>15.4</td>\n      <td>-0.22</td>\n      <td>15.18</td>\n      <td>0.74</td>\n      <td>0.000067</td>\n      <td>0.1</td>\n      <td>0.00898</td>\n      <td>DZ9</td>\n      <td>5600.0</td>\n      <td>16773089</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "source": [
    "star_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1100 entries, 1 to 1235\nData columns (total 11 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   Abs MagMv             1100 non-null   float64\n 1   Bolo CorrBC(Temp)     1100 non-null   float64\n 2   Bolo MagMbol          1100 non-null   float64\n 3   Color IndexB-V        1100 non-null   float64\n 4   LuminosityLstar/Lsun  1100 non-null   float64\n 5   MassMstar/Msun        1100 non-null   float64\n 6   RadiusRstar/Rsun      1100 non-null   float64\n 7   StellarType           1100 non-null   object \n 8   TempK                 1100 non-null   float64\n 9   color_decimal         1100 non-null   int64  \n 10  star_family           1100 non-null   object \ndtypes: float64(8), int64(1), object(2)\nmemory usage: 103.1+ KB\n"
     ]
    }
   ],
   "source": [
    "star_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset: 100%|██████████| 25/25 [00:15<00:00,  1.67it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:05<00:00,  5.25s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 59.52it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = star_data.profile_report(title='EDA of star dataset using Pandas Profiling')\n",
    "# save the minified report\n",
    "profile.to_file(output_file=\"star.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up x and y variables\n",
    "X = star_data[['Abs MagMv', 'Bolo CorrBC(Temp)', 'Bolo MagMbol', 'Color IndexB-V', 'LuminosityLstar/Lsun', 'MassMstar/Msun', 'RadiusRstar/Rsun', 'TempK', 'color_decimal']]\n",
    "y = star_data['star_family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and testing set (testing is 20% of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=14)"
   ]
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 364
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = lr.predict(X_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "execution_count": 366
    }
   ],
   "source": [
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.22727\nPrecision = 0.12487\nRecall = 0.22727\nF1 score = 0.13313\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           A       0.00      0.00      0.00        13\n           B       0.00      0.00      0.00        19\n           C       0.00      0.00      0.00        18\n           D       0.00      0.00      0.00         8\n           F       0.00      0.00      0.00        20\n           G       0.10      0.86      0.18        14\n           K       0.00      0.00      0.00        16\n           M       0.00      0.00      0.00        14\n           N       0.50      0.08      0.13        13\n           O       0.00      0.00      0.00        16\n           R       0.27      0.25      0.26        16\n           S       0.00      0.00      0.00        15\n           W       0.40      0.87      0.55        38\n\n    accuracy                           0.23       220\n   macro avg       0.10      0.16      0.09       220\nweighted avg       0.12      0.23      0.13       220\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, average_precision_score, f1_score, classification_report, accuracy_score, plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix\n"
   ]
  },
  {
   "source": [
    "## K Nearest Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "metadata": {},
     "execution_count": 368
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_yhat_train = knn.predict(X_train)\n",
    "knn_y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           A       0.67      0.77      0.71        13\n           B       0.87      0.68      0.76        19\n           C       0.14      0.22      0.17        18\n           D       0.73      1.00      0.84         8\n           F       0.89      0.85      0.87        20\n           G       0.55      0.79      0.65        14\n           K       0.44      0.44      0.44        16\n           M       0.17      0.29      0.22        14\n           N       0.00      0.00      0.00        13\n           O       0.00      0.00      0.00        16\n           R       0.12      0.06      0.08        16\n           S       0.00      0.00      0.00        15\n           W       0.61      0.71      0.66        38\n\n    accuracy                           0.46       220\n   macro avg       0.40      0.45      0.42       220\nweighted avg       0.43      0.46      0.44       220\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.46364\nPrecision = 0.42628\nRecall = 0.46364\nF1 score = 0.43861\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, knn_y_pred)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, knn_y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, knn_y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, knn_y_pred, average='weighted')))"
   ]
  },
  {
   "source": [
    "## Decision Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "metadata": {},
     "execution_count": 371
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_leaf=3)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_yhat_train = dt.predict(X_train)\n",
    "dt_y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.51364\nPrecision = 0.52591\nRecall = 0.51364\nF1 score = 0.51709\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, dt_y_pred)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, dt_y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, dt_y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, dt_y_pred, average='weighted')))"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 382
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_yhat_train = rf.predict(X_train)\n",
    "rf_y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.91818\nPrecision = 0.91892\nRecall = 0.91818\nF1 score = 0.91588\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, rf_y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, rf_y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, rf_y_pred, average='weighted')))"
   ]
  },
  {
   "source": [
    "TODO:   \n",
    "-Logistic regression   \n",
    "-Support vector machine  \n",
    "-Naive Bayes\n",
    "\n",
    "Split the first letter of each star off, put in new column. I will just predict that part since there are 1100 unique rows for the stars.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}